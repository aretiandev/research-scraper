{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9722fea-7375-40cd-be0d-91abd54100a6",
   "metadata": {},
   "source": [
    "# Post processing scraped data\n",
    "\n",
    "This notebook processes the scraped data from Portal de la Reserca to create the Nodelist and Edgelist to plot in Gephi."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d27f59b-cfdd-4f38-bcf0-38e4e5e44cd1",
   "metadata": {},
   "source": [
    "# Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553d9af1-da9d-4718-b27a-45d4ef954fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from ast import literal_eval\n",
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1533c6a-f0ad-4357-b6a0-f689e647fdf3",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae84a20d-e53d-44ef-8531-9acea4b5b4c8",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Get edgelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fafc0784-e9ed-4ffb-89ce-1024f95b3a21",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Pre-process edgelist\n",
    "# papers0_df = pd.read_csv('./data/papers_0.csv')\n",
    "# papers1_df = pd.read_csv('./data/papers_1.csv')\n",
    "# papers_df = papers0_df.append(papers1_df)\n",
    "# papers_df = papers_df.drop_duplicates()\n",
    "# papers_df.to_csv('./data/papers.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd169c8c-c782-41ca-bb57-b23543694331",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load edgelist\n",
    "papers_df = pd.read_csv('./data/papers.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a6af0d-cb75-4703-bcf7-33bf743823e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# papers_df_backup = papers_df.copy()\n",
    "# papers_df = papers_df_backup.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd1a8a1-7f01-4a1c-9a2a-a547fde491bc",
   "metadata": {},
   "source": [
    "## Get researchers of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638ed263-ec72-4ffc-8980-74abcfdc0398",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df = pd.read_csv('./data/nodelist.csv')\n",
    "\n",
    "# Select institution\n",
    "institution = 'IGTP'\n",
    "\n",
    "# Filter researchers\n",
    "res_df_inst = res_df.loc[res_df['institution'] == institution]\n",
    "res_inst = res_df_inst['id'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6fecb30-b056-4f94-8c79-a9f8081f0b30",
   "metadata": {},
   "source": [
    "# Calculate collaborations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feaea551-4af2-40be-acd0-5fb084d56c84",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5027fcf-ab15-4128-b2fb-8ded495f3120",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def convert_to_list(x):\n",
    "    \"\"\"Convert string column to list\"\"\"\n",
    "    try:\n",
    "        result = literal_eval(x)\n",
    "    except ValueError:\n",
    "        result = np.nan\n",
    "    return result\n",
    "\n",
    "def belongs_to_list(row, df):\n",
    "    try:\n",
    "        result = bool(set(row['orcids']) & set(df))\n",
    "    except TypeError:\n",
    "        result = False\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6686e470-a76e-441f-81a2-13e4cf6deec7",
   "metadata": {},
   "source": [
    "## Filter papers based on institution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93fef30f-6677-4435-b5f8-7239445d3ace",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convert strings to list of coauthors\n",
    "papers_df['orcids'] = papers_df['orcids'].apply(lambda x: convert_to_list(x))\n",
    "\n",
    "# Identify authors in institution\n",
    "institution_df = res_inst\n",
    "mask = papers_df.apply(lambda x: belongs_to_list(x, institution_df), axis=1)\n",
    "\n",
    "selected_df = papers_df[mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc4b6154-c28b-44fc-a245-0334aa19f466",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Save papers of institution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ad3091-ed0e-4d4b-94a5-9dc0c5a906f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "selected_df.to_csv(f'./data/nodelist_{institution}.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b70ad1-888d-47f8-850b-823804664f93",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load papers\n",
    "# selected_df = pd.read_csv('./data/nodelist_IGTP.csv', converters = {'orcids': eval})\n",
    "\n",
    "# Test with n papers for debugging (max 2800)\n",
    "# n = 100\n",
    "# selected_df = selected_df[:n]\n",
    "\n",
    "# Get papers column\n",
    "papers = selected_df['orcids'].copy()\n",
    "papers = papers.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e514ca-a0ae-471f-bf64-df8b1901dd04",
   "metadata": {},
   "source": [
    "## Create papers matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662ca37b-e24a-4fb7-a0d0-9bfe08400bce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get unique list of authors from papers\n",
    "authors_index = list(set(papers.sum()))\n",
    "\n",
    "authors_index.sort()\n",
    "\n",
    "# Create boolean matrix with papers\n",
    "paper_bool_df = pd.DataFrame(columns=authors_index, index=range(len(papers)))\n",
    "\n",
    "for i, paper in enumerate(papers):\n",
    "    paper_bool_df.loc[i,:] = 0\n",
    "    for orcid in paper:\n",
    "        paper_bool_df.loc[i,orcid] = 1\n",
    "        \n",
    "# Create papers matrix in numpy\n",
    "papers_mat = paper_bool_df.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff6c5a5-158e-448c-91be-70471e0033bb",
   "metadata": {},
   "source": [
    "## Create boolean matrix of coauthor combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03e65d4-1328-4407-9875-27e2cfdf6d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build collaboration vector to store results\n",
    "n_authors = len(authors_index)\n",
    "collabs_length = int(n_authors*(n_authors+1)/2 - n_authors) \n",
    "collabs = np.zeros(shape=(collabs_length))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "385010a8-f671-4872-abc1-12178ad83e2b",
   "metadata": {},
   "source": [
    "## Main loop: calculate collaborations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a4fff4-29f3-4b3b-b6b5-df6240937ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store copy of papers_mat for iterative updating\n",
    "papers_mat_i = papers_mat\n",
    "\n",
    "# Initialize writing position\n",
    "start_pos = 0\n",
    "\n",
    "for i in range(0, n_authors-1): #last author loop is unnecessary\n",
    "    print(f\"Progress: {i/(n_authors-2)*100:.0f}%.\", end=\"\\r\")\n",
    "    \n",
    "    # Initialize matrix\n",
    "    C = np.identity(n_authors-i)\n",
    "    C = C[:,1:]\n",
    "    C[0] = 1\n",
    "    \n",
    "    # Main inner product\n",
    "    result = np.dot(papers_mat_i, C)\n",
    "\n",
    "    # Calculate number of collaborations\n",
    "    result = result - 1\n",
    "    result = result.clip(0)\n",
    "    collabs_author = result.sum(axis=0)\n",
    "\n",
    "    # Store in collabs vector\n",
    "    end_pos = start_pos + n_authors - i - 1\n",
    "    \n",
    "    collabs[start_pos:end_pos] = collabs_author\n",
    "    \n",
    "    # Update start_pos for writing next loop\n",
    "    start_pos = end_pos \n",
    "    \n",
    "    # Remove first author from papers_mat for next loop\n",
    "    papers_mat_i = papers_mat_i[:,1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf43e5d0-adf6-41a4-961c-27f59d8b1226",
   "metadata": {},
   "source": [
    "## Create Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2652d6d4-5254-456c-93ec-2e9b29bd13b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "author_combinations = combinations(authors_index,2)\n",
    "collabs_df = pd.DataFrame(list(author_combinations), columns=['source', 'target'])\n",
    "collabs_df['value']=collabs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48167e8b-61e0-4265-8450-c3ff3220145b",
   "metadata": {},
   "source": [
    "## Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70bbb556-30ff-4cca-9701-ed298a366e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "collabs_df.to_csv(f'./data/edgelist_{institution}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e463cb19-4f60-4644-811a-db88b373364d",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Automated Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e15fe3e8-0142-4872-867a-51b2d2b3558f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be02552d-aa30-455f-a12c-c53217ddbf0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_list(x):\n",
    "    \"\"\"Convert string column to list\"\"\"\n",
    "    try:\n",
    "        result = literal_eval(x)\n",
    "    except ValueError:\n",
    "        result = np.nan\n",
    "    return result\n",
    "\n",
    "def belongs_to_list(row, df):\n",
    "    try:\n",
    "        result = bool(set(row['orcids']) & set(df))\n",
    "    except TypeError:\n",
    "        result = False\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d381627c-a51d-43aa-9182-0989dd24aa47",
   "metadata": {},
   "source": [
    "## Define main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006b9d55-3122-43a8-b022-9696dee21a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load edgelist\n",
    "papers_df = pd.read_csv('./data/papers.csv')\n",
    "res_df = pd.read_csv('./data/nodelist.csv')\n",
    "\n",
    "def calculate_collaborations(institution, papers_df, res_df, save=False, threshold=None):\n",
    "\n",
    "    # Filter researchers\n",
    "    res_df_inst = res_df.loc[res_df['institution'] == institution]\n",
    "    res_inst = res_df_inst['id'].unique()\n",
    "\n",
    "    # Convert strings to list of coauthors\n",
    "    papers_df['orcids'] = papers_df['orcids'].apply(lambda x: convert_to_list(x))\n",
    "\n",
    "    # Identify authors in institution\n",
    "    institution_df = res_inst\n",
    "    mask = papers_df.apply(lambda x: belongs_to_list(x, institution_df), axis=1)\n",
    "\n",
    "    selected_df = papers_df[mask]\n",
    "    \n",
    "    # Test with n papers for debugging (max 2800)\n",
    "    if threshold:\n",
    "        selected_df = selected_df[:threshold]\n",
    "\n",
    "    # Get papers column\n",
    "    papers = selected_df['orcids'].copy()\n",
    "    papers = papers.reset_index(drop=True)\n",
    "\n",
    "    # Get unique list of authors from papers\n",
    "    authors_index = list(set(papers.sum()))\n",
    "\n",
    "    authors_index.sort()\n",
    "\n",
    "    # Create boolean matrix with papers\n",
    "    paper_bool_df = pd.DataFrame(columns=authors_index, index=range(len(papers)))\n",
    "\n",
    "    for i, paper in enumerate(papers):\n",
    "        paper_bool_df.loc[i,:] = 0\n",
    "        for orcid in paper:\n",
    "            paper_bool_df.loc[i,orcid] = 1\n",
    "\n",
    "    # Create papers matrix in numpy\n",
    "    papers_mat = paper_bool_df.to_numpy()\n",
    "\n",
    "    # Build collaboration vector to store results\n",
    "    n_authors = len(authors_index)\n",
    "    collabs_length = int(n_authors*(n_authors+1)/2 - n_authors) \n",
    "    collabs = np.zeros(shape=(collabs_length))\n",
    "\n",
    "    # Store copy of papers_mat for iterative updating\n",
    "    papers_mat_i = papers_mat\n",
    "\n",
    "    # Initialize writing position\n",
    "    start_pos = 0\n",
    "\n",
    "    for i in range(0, n_authors-1): #last author loop is unnecessary\n",
    "        print(f\"Progress: {i/(n_authors-2)*100:.0f}%.\", end=\"\\r\")\n",
    "\n",
    "        # Initialize matrix\n",
    "        C = np.identity(n_authors-i)\n",
    "        C = C[:,1:]\n",
    "        C[0] = 1\n",
    "\n",
    "        # Main inner product\n",
    "        result = np.dot(papers_mat_i, C)\n",
    "\n",
    "        # Calculate number of collaborations\n",
    "        result = result - 1\n",
    "        result = result.clip(0)\n",
    "        collabs_author = result.sum(axis=0)\n",
    "\n",
    "        # Store in collabs vector\n",
    "        end_pos = start_pos + n_authors - i - 1\n",
    "\n",
    "        collabs[start_pos:end_pos] = collabs_author\n",
    "\n",
    "        # Update start_pos for writing next loop\n",
    "        start_pos = end_pos \n",
    "\n",
    "        # Remove first author from papers_mat for next loop\n",
    "        papers_mat_i = papers_mat_i[:,1:]\n",
    "\n",
    "    author_combinations = combinations(authors_index,2)\n",
    "    collabs_df = pd.DataFrame(list(author_combinations), columns=['source', 'target'])\n",
    "    collabs_df['value']=collabs\n",
    "\n",
    "    if save:\n",
    "        collabs_df.to_csv(f'./data/edgelist_{institution}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a627dcb7-49b2-44da-bdb5-280165222b8a",
   "metadata": {},
   "source": [
    "## Execute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41307be8-77a1-4b49-abcc-6e533bc33931",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select institution\n",
    "institution_list = ['IGTP']\n",
    "\n",
    "for institution in institution_list:\n",
    "    calculate_collaborations(institution, papers_df, res_df, save=True, threshold=100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
