{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9722fea-7375-40cd-be0d-91abd54100a6",
   "metadata": {},
   "source": [
    "# Post processing scraped data\n",
    "\n",
    "This notebook processes the scraped data from Portal de la Reserca to create the Nodelist and Edgelist to plot in Gephi."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d27f59b-cfdd-4f38-bcf0-38e4e5e44cd1",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "553d9af1-da9d-4718-b27a-45d4ef954fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from ast import literal_eval\n",
    "from itertools import combinations\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1533c6a-f0ad-4357-b6a0-f689e647fdf3",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc4de9a-b4b8-481a-9c67-9ca127c0429c",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cfc57f49-adbb-49dd-b756-42e94ca06496",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def convert_to_list(x):\n",
    "    \"\"\"Convert string column to list\"\"\"\n",
    "    try:\n",
    "        result = literal_eval(x)\n",
    "    except ValueError:\n",
    "        result = np.nan\n",
    "    return result\n",
    "\n",
    "def belongs_to_list(row, df):\n",
    "    try:\n",
    "        result = bool(set(row['orcids']) & set(df))\n",
    "    except TypeError:\n",
    "        result = False\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d665e1b0-d48e-4b3c-92ad-2821cd98d9f4",
   "metadata": {},
   "source": [
    "## Get researchers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2afe4212-4914-4582-a060-c120601ab8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df = pd.read_csv('./data/nodelist.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a5d3c8-6249-48ae-aaf9-3f16dc12e501",
   "metadata": {},
   "source": [
    "### Select institution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "6ffd1c5d-bf27-4665-9dc7-4bca22150d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select institution\n",
    "institution = 'IGTP'\n",
    "# institution = 'UPC'\n",
    "# institution = 'UB'\n",
    "# institution = 'UPF'\n",
    "# institution = 'UVic-UCC'\n",
    "# institution = 'UOC'\n",
    "\n",
    "# Filter researchers\n",
    "res_df_inst = res_df.loc[res_df['institution'] == institution]\n",
    "res_inst = res_df_inst['id'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff2b073-4e9f-4fde-9de2-649da41c106c",
   "metadata": {},
   "source": [
    "### Save researchers from institution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f7facecd-9ed8-4d01-9a69-f2818d7515fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# res_df_inst.to_csv(f'./data/nodelist_{institution}.csv', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae84a20d-e53d-44ef-8531-9acea4b5b4c8",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Get papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "fafc0784-e9ed-4ffb-89ce-1024f95b3a21",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Pre-process edgelist\n",
    "# papers0_df = pd.read_csv('./data/papers_0.csv')\n",
    "# papers1_df = pd.read_csv('./data/papers_1.csv')\n",
    "# papers_df = papers0_df.append(papers1_df)\n",
    "# papers_df = papers_df.drop_duplicates()\n",
    "# papers_df.to_csv('./data/papers.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e64ca3db-96b9-4b9e-baf5-a2026082f8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load papers\n",
    "# papers_df = pd.read_csv('./data/papers.csv')\n",
    "# Convert strings to list of coauthors\n",
    "# papers_df['orcids'] = papers_df['orcids'].apply(lambda x: convert_to_list(x))\n",
    "\n",
    "# papers_df_backup = papers_df.copy()\n",
    "papers_df = papers_df_backup.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6686e470-a76e-441f-81a2-13e4cf6deec7",
   "metadata": {},
   "source": [
    "## Filter papers based on institution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "93fef30f-6677-4435-b5f8-7239445d3ace",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Identify authors in institution\n",
    "institution_df = res_inst\n",
    "mask = papers_df.apply(lambda x: belongs_to_list(x, institution_df), axis=1)\n",
    "\n",
    "selected_df = papers_df[mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc4b6154-c28b-44fc-a245-0334aa19f466",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Save papers of institution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "1a99289a-d23b-46ed-9688-6101f2f61adb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "selected_df.to_csv(f'./data/papers_{institution}.csv', index=None)\n",
    "\n",
    "# Load papers\n",
    "# selected_df = pd.read_csv(f'./data/papers_{institution}.csv', converters = {'orcids': eval})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "0e054149-b2fe-4788-99ca-94a0cf0b724e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get papers column\n",
    "papers = selected_df['orcids'].copy()\n",
    "papers = papers.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b666b655-f6c6-49d9-85b8-283eb7183408",
   "metadata": {},
   "source": [
    "## Extract random sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "7e046c7a-a46c-4e49-805a-aba03365fb30",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 100\n",
    "papers = papers.sample(threshold, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e514ca-a0ae-471f-bf64-df8b1901dd04",
   "metadata": {},
   "source": [
    "## Create papers matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "662ca37b-e24a-4fb7-a0d0-9bfe08400bce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get unique list of authors from papers\n",
    "authors_index = list(set(papers.sum()))\n",
    "\n",
    "authors_index.sort()\n",
    "\n",
    "# Create boolean matrix with papers\n",
    "paper_bool_df = pd.DataFrame(columns=authors_index, index=range(len(papers)))\n",
    "\n",
    "for i, paper in enumerate(papers):\n",
    "    paper_bool_df.loc[i,:] = 0\n",
    "    for orcid in paper:\n",
    "        paper_bool_df.loc[i,orcid] = 1\n",
    "        \n",
    "# Create papers matrix in numpy\n",
    "papers_mat = paper_bool_df.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "317e5f9a-2365-42a4-a3ec-97d11d548cdc",
   "metadata": {},
   "source": [
    "# Calculate collaborations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "385010a8-f671-4872-abc1-12178ad83e2b",
   "metadata": {},
   "source": [
    "## Main loop: calculate collaborations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e512511e-5ea5-48a8-ae8a-a056001994bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 100%.\r"
     ]
    }
   ],
   "source": [
    "# Build collaboration vector to store results\n",
    "n_authors = len(authors_index)\n",
    "collabs_length = int(n_authors*(n_authors+1)/2 - n_authors) \n",
    "collabs = np.zeros(shape=(collabs_length))\n",
    "\n",
    "# Store copy of papers_mat for iterative updating\n",
    "papers_mat_i = papers_mat\n",
    "\n",
    "# Initialize writing position\n",
    "start_pos = 0\n",
    "\n",
    "for i in range(0, n_authors-1): #last author loop is unnecessary\n",
    "    print(f\"Progress: {i/(n_authors-2)*100:.0f}%.\", end=\"\\r\")\n",
    "    \n",
    "    # Initialize matrix\n",
    "    C = np.identity(n_authors-i)\n",
    "    C = C[:,1:]\n",
    "    C[0] = 1\n",
    "    \n",
    "    # Main inner product\n",
    "    result = np.dot(papers_mat_i, C)\n",
    "\n",
    "    # Calculate number of collaborations\n",
    "    result = result - 1\n",
    "    result = result.clip(0)\n",
    "    collabs_author = result.sum(axis=0)\n",
    "\n",
    "    # Store in collabs vector\n",
    "    end_pos = start_pos + n_authors - i - 1\n",
    "    \n",
    "    collabs[start_pos:end_pos] = collabs_author\n",
    "    \n",
    "    # Update start_pos for writing next loop\n",
    "    start_pos = end_pos \n",
    "    \n",
    "    # Remove first author from papers_mat for next loop\n",
    "    papers_mat_i = papers_mat_i[:,1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf43e5d0-adf6-41a4-961c-27f59d8b1226",
   "metadata": {},
   "source": [
    "## Create Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "2652d6d4-5254-456c-93ec-2e9b29bd13b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "author_combinations = combinations(authors_index,2)\n",
    "collabs_df = pd.DataFrame(list(author_combinations), columns=['source', 'target'])\n",
    "collabs_df['value']=collabs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48167e8b-61e0-4265-8450-c3ff3220145b",
   "metadata": {},
   "source": [
    "## Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "70bbb556-30ff-4cca-9701-ed298a366e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "collabs_df.to_csv(f'./data/edgelist_{institution}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e15fe3e8-0142-4872-867a-51b2d2b3558f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be02552d-aa30-455f-a12c-c53217ddbf0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_list(x):\n",
    "    \"\"\"Convert string column to list\"\"\"\n",
    "    try:\n",
    "        result = literal_eval(x)\n",
    "    except ValueError:\n",
    "        result = np.nan\n",
    "    return result\n",
    "\n",
    "def belongs_to_list(row, df):\n",
    "    try:\n",
    "        result = bool(set(row['orcids']) & set(df))\n",
    "    except TypeError:\n",
    "        result = False\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d381627c-a51d-43aa-9182-0989dd24aa47",
   "metadata": {},
   "source": [
    "## Define main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006b9d55-3122-43a8-b022-9696dee21a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load edgelist\n",
    "papers_df = pd.read_csv('./data/papers.csv')\n",
    "res_df = pd.read_csv('./data/nodelist.csv')\n",
    "\n",
    "def calculate_collaborations(institution, papers_df, res_df, save=False, threshold=None):\n",
    "\n",
    "    # Filter researchers\n",
    "    res_df_inst = res_df.loc[res_df['institution'] == institution]\n",
    "    res_inst = res_df_inst['id'].unique()\n",
    "\n",
    "    # Convert strings to list of coauthors\n",
    "    papers_df['orcids'] = papers_df['orcids'].apply(lambda x: convert_to_list(x))\n",
    "\n",
    "    # Identify authors in institution\n",
    "    institution_df = res_inst\n",
    "    mask = papers_df.apply(lambda x: belongs_to_list(x, institution_df), axis=1)\n",
    "\n",
    "    selected_df = papers_df[mask]\n",
    "    \n",
    "    # Test with n papers for debugging (max 2800)\n",
    "    if threshold:\n",
    "        selected_df = selected_df[:threshold]\n",
    "\n",
    "    # Get papers column\n",
    "    papers = selected_df['orcids'].copy()\n",
    "    papers = papers.reset_index(drop=True)\n",
    "\n",
    "    # Get unique list of authors from papers\n",
    "    authors_index = list(set(papers.sum()))\n",
    "\n",
    "    authors_index.sort()\n",
    "\n",
    "    # Create boolean matrix with papers\n",
    "    paper_bool_df = pd.DataFrame(columns=authors_index, index=range(len(papers)))\n",
    "\n",
    "    for i, paper in enumerate(papers):\n",
    "        paper_bool_df.loc[i,:] = 0\n",
    "        for orcid in paper:\n",
    "            paper_bool_df.loc[i,orcid] = 1\n",
    "\n",
    "    # Create papers matrix in numpy\n",
    "    papers_mat = paper_bool_df.to_numpy()\n",
    "\n",
    "    # Build collaboration vector to store results\n",
    "    n_authors = len(authors_index)\n",
    "    collabs_length = int(n_authors*(n_authors+1)/2 - n_authors) \n",
    "    collabs = np.zeros(shape=(collabs_length))\n",
    "\n",
    "    # Store copy of papers_mat for iterative updating\n",
    "    papers_mat_i = papers_mat\n",
    "\n",
    "    # Initialize writing position\n",
    "    start_pos = 0\n",
    "\n",
    "    for i in range(0, n_authors-1): #last author loop is unnecessary\n",
    "        print(f\"Progress: {i/(n_authors-2)*100:.0f}%.\", end=\"\\r\")\n",
    "\n",
    "        # Initialize matrix\n",
    "        C = np.identity(n_authors-i)\n",
    "        C = C[:,1:]\n",
    "        C[0] = 1\n",
    "\n",
    "        # Main inner product\n",
    "        result = np.dot(papers_mat_i, C)\n",
    "\n",
    "        # Calculate number of collaborations\n",
    "        result = result - 1\n",
    "        result = result.clip(0)\n",
    "        collabs_author = result.sum(axis=0)\n",
    "\n",
    "        # Store in collabs vector\n",
    "        end_pos = start_pos + n_authors - i - 1\n",
    "\n",
    "        collabs[start_pos:end_pos] = collabs_author\n",
    "\n",
    "        # Update start_pos for writing next loop\n",
    "        start_pos = end_pos \n",
    "\n",
    "        # Remove first author from papers_mat for next loop\n",
    "        papers_mat_i = papers_mat_i[:,1:]\n",
    "\n",
    "    author_combinations = combinations(authors_index,2)\n",
    "    collabs_df = pd.DataFrame(list(author_combinations), columns=['source', 'target'])\n",
    "    collabs_df['value']=collabs\n",
    "\n",
    "    if save:\n",
    "        collabs_df.to_csv(f'./data/edgelist_{institution}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a627dcb7-49b2-44da-bdb5-280165222b8a",
   "metadata": {},
   "source": [
    "## Execute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41307be8-77a1-4b49-abcc-6e533bc33931",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select institution\n",
    "institution_list = ['IGTP']\n",
    "\n",
    "for institution in institution_list:\n",
    "    calculate_collaborations(institution, papers_df, res_df, save=True, threshold=100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
