{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9722fea-7375-40cd-be0d-91abd54100a6",
   "metadata": {},
   "source": [
    "# Post processing scraped data\n",
    "\n",
    "This notebook processes the scraped data from Portal de la Reserca to create the Nodelist and Edgelist to plot in Gephi."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d27f59b-cfdd-4f38-bcf0-38e4e5e44cd1",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "553d9af1-da9d-4718-b27a-45d4ef954fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from ast import literal_eval\n",
    "from itertools import combinations\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1533c6a-f0ad-4357-b6a0-f689e647fdf3",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d665e1b0-d48e-4b3c-92ad-2821cd98d9f4",
   "metadata": {},
   "source": [
    "## Get researchers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a5d3c8-6249-48ae-aaf9-3f16dc12e501",
   "metadata": {},
   "source": [
    "### Select institution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b6c38d9a-4a34-4dbf-b8ac-70d21d1b9149",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select institution\n",
    "institution = 'IGTP'\n",
    "# institution = 'UPC'\n",
    "# institution = 'UB'\n",
    "# institution = 'UPF'\n",
    "# institution = 'UVic-UCC'\n",
    "# institution = 'UOC'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc4b6154-c28b-44fc-a245-0334aa19f466",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Get papers of institution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5f440642-e060-4a79-b8e3-d51469842f37",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load authors from papers dataset\n",
    "papers = pd.read_csv(f'./data/papers_{institution}.csv', converters = {'orcids': eval}, usecols=['orcids'])\n",
    "\n",
    "# Get papers column\n",
    "# authors = papers_inst['orcids'].copy()\n",
    "papers = papers['orcids']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b666b655-f6c6-49d9-85b8-283eb7183408",
   "metadata": {},
   "source": [
    "## Extract random sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7e046c7a-a46c-4e49-805a-aba03365fb30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# threshold = 400\n",
    "# papers = papers.sample(threshold, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e514ca-a0ae-471f-bf64-df8b1901dd04",
   "metadata": {},
   "source": [
    "## Create papers matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9b015f88-a538-4a11-9412-e0d4f2e2e6c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get unique list of authors from papers\n",
    "authors_papers = list(set(papers.sum()))\n",
    "authors_papers.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "883a9482-eb47-4e59-ae99-d6743c6c380c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine with list of authors from institution\n",
    "authors_inst = pd.read_csv(f'./data/nodelist_{institution}.csv', usecols=['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e970e28d-4194-4128-b056-73b33d6141c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "authors_inst = authors_inst['id']\n",
    "authors_inst = authors_inst.unique()\n",
    "authors_inst.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4120c78d-6690-44e2-b17e-c2d9406cfa25",
   "metadata": {},
   "outputs": [],
   "source": [
    "authors_index = list(set(authors_papers) & set(authors_inst))\n",
    "authors_index.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a2baea4f-a578-4a21-a2cd-6f1946566cf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "625"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(authors_inst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "423d33f7-9e24-431e-9423-3066ca632d74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1398"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(authors_papers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "18d41c53-9c03-4d45-b212-d2c96c3f2cda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "510"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(authors_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4bfc5267-7e7a-4e73-804e-dd78992d7ede",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create boolean matrix with papers\n",
    "paper_bool_df = pd.DataFrame(columns=authors_index, index=range(len(papers)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cf701f93-724e-4463-8a5e-ec354396080c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7966, 625)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paper_bool_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ebf220-08b9-4fd7-ac7d-5f93b47a0656",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i, paper in enumerate(papers):\n",
    "    paper_bool_df.loc[i,:] = 0\n",
    "    for orcid in paper:\n",
    "        paper_bool_df.loc[i,orcid] = 1\n",
    "        \n",
    "# paper_bool_df = pd.read_csv(f'./data/paper_author_matrix_{institution}.csv')\n",
    "# Convert to numpy\n",
    "papers_mat = paper_bool_df.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "317e5f9a-2365-42a4-a3ec-97d11d548cdc",
   "metadata": {},
   "source": [
    "# Calculate collaborations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "385010a8-f671-4872-abc1-12178ad83e2b",
   "metadata": {},
   "source": [
    "## Main loop: calculate collaborations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054d4151-a1f8-4ad1-9733-613010306362",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"running\")\n",
    "# Build collaboration vector to store results\n",
    "n_authors = len(authors_index)\n",
    "collabs_length = int(n_authors*(n_authors+1)/2 - n_authors) \n",
    "print(\"generating collabs vector\")\n",
    "collabs = np.zeros(shape=(collabs_length))\n",
    "\n",
    "# Store copy of papers_mat for iterative updating\n",
    "papers_mat_i = papers_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22b3485-57c0-4e9d-b639-4317ec325f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Running main loop\")\n",
    "# Initialize writing position\n",
    "start_pos = 0\n",
    "\n",
    "for i in range(0, n_authors-1): #last author loop is unnecessary\n",
    "    print(f\"Progress: {i/(n_authors-2)*100:.0f}%. Researcher: {i}/{n_authors}.\", end=\"\\r\", flush=True)\n",
    "    \n",
    "    # Initialize matrix\n",
    "    \n",
    "    print(f\"Progress: {i/(n_authors-2)*100:.0f}%. Researcher: {i}/{n_authors}. Generating Identity matrix.\", end=\"\\r\", flush=True)\n",
    "    C = np.identity(n_authors-i)\n",
    "    C = C[:,1:]\n",
    "    C[0] = 1\n",
    "    \n",
    "    # Main inner product\n",
    "    print(f\"Progress: {i/(n_authors-2)*100:.0f}%. Researcher: {i}/{n_authors}. Inner product.             \", end=\"\\r\", flush=True)\n",
    "    result = np.dot(papers_mat_i, C)\n",
    "\n",
    "    # Calculate number of collaborations\n",
    "    print(f\"Progress: {i/(n_authors-2)*100:.0f}%. Researcher: {i}/{n_authors}. Calculating collaborations.\", end=\"\\r\", flush=True)\n",
    "    result = result - 1\n",
    "    result = result.clip(0)\n",
    "    collabs_author = result.sum(axis=0)\n",
    "\n",
    "    # Store in collabs vector\n",
    "    end_pos = start_pos + n_authors - i - 1\n",
    "    \n",
    "    print(f\"Progress: {i/(n_authors-2)*100:.0f}%. Researcher: {i}/{n_authors}. Storing results.           \", end=\"\\r\", flush=True)\n",
    "    collabs[start_pos:end_pos] = collabs_author\n",
    "    \n",
    "    # Update start_pos for writing next loop\n",
    "    start_pos = end_pos \n",
    "    \n",
    "    # Remove first author from papers_mat for next loop\n",
    "    print(f\"Progress: {i/(n_authors-2)*100:.0f}%. Researcher: {i}/{n_authors}. Updating matrix next loop. \", end=\"\\r\", flush=True)\n",
    "    papers_mat_i = papers_mat_i[:,1:]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf43e5d0-adf6-41a4-961c-27f59d8b1226",
   "metadata": {},
   "source": [
    "## Create Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2652d6d4-5254-456c-93ec-2e9b29bd13b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "author_combinations = combinations(authors_index,2)\n",
    "collabs_df = pd.DataFrame(list(author_combinations), columns=['source', 'target'])\n",
    "collabs_df['value']=collabs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48167e8b-61e0-4265-8450-c3ff3220145b",
   "metadata": {},
   "source": [
    "## Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70bbb556-30ff-4cca-9701-ed298a366e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "collabs_df.to_csv(f'./data/edgelist_{institution}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e15fe3e8-0142-4872-867a-51b2d2b3558f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be02552d-aa30-455f-a12c-c53217ddbf0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_list(x):\n",
    "    \"\"\"Convert string column to list\"\"\"\n",
    "    try:\n",
    "        result = literal_eval(x)\n",
    "    except ValueError:\n",
    "        result = np.nan\n",
    "    return result\n",
    "\n",
    "def belongs_to_list(row, df):\n",
    "    try:\n",
    "        result = bool(set(row['orcids']) & set(df))\n",
    "    except TypeError:\n",
    "        result = False\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d381627c-a51d-43aa-9182-0989dd24aa47",
   "metadata": {},
   "source": [
    "## Define main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006b9d55-3122-43a8-b022-9696dee21a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load edgelist\n",
    "papers_df = pd.read_csv('./data/papers.csv')\n",
    "res_df = pd.read_csv('./data/nodelist.csv')\n",
    "\n",
    "def calculate_collaborations(institution, papers_df, res_df, save=False, threshold=None):\n",
    "\n",
    "    # Filter researchers\n",
    "    res_df_inst = res_df.loc[res_df['institution'] == institution]\n",
    "    res_inst = res_df_inst['id'].unique()\n",
    "\n",
    "    # Convert strings to list of coauthors\n",
    "    papers_df['orcids'] = papers_df['orcids'].apply(lambda x: convert_to_list(x))\n",
    "\n",
    "    # Identify authors in institution\n",
    "    institution_df = res_inst\n",
    "    mask = papers_df.apply(lambda x: belongs_to_list(x, institution_df), axis=1)\n",
    "\n",
    "    selected_df = papers_df[mask]\n",
    "    \n",
    "    # Test with n papers for debugging (max 2800)\n",
    "    if threshold:\n",
    "        selected_df = selected_df[:threshold]\n",
    "\n",
    "    # Get papers column\n",
    "    papers = selected_df['orcids'].copy()\n",
    "    papers = papers.reset_index(drop=True)\n",
    "\n",
    "    # Get unique list of authors from papers\n",
    "    authors_index = list(set(papers.sum()))\n",
    "\n",
    "    authors_index.sort()\n",
    "\n",
    "    # Create boolean matrix with papers\n",
    "    paper_bool_df = pd.DataFrame(columns=authors_index, index=range(len(papers)))\n",
    "\n",
    "    for i, paper in enumerate(papers):\n",
    "        paper_bool_df.loc[i,:] = 0\n",
    "        for orcid in paper:\n",
    "            paper_bool_df.loc[i,orcid] = 1\n",
    "\n",
    "    # Create papers matrix in numpy\n",
    "    papers_mat = paper_bool_df.to_numpy()\n",
    "\n",
    "    # Build collaboration vector to store results\n",
    "    n_authors = len(authors_index)\n",
    "    collabs_length = int(n_authors*(n_authors+1)/2 - n_authors) \n",
    "    collabs = np.zeros(shape=(collabs_length))\n",
    "\n",
    "    # Store copy of papers_mat for iterative updating\n",
    "    papers_mat_i = papers_mat\n",
    "\n",
    "    # Initialize writing position\n",
    "    start_pos = 0\n",
    "\n",
    "    for i in range(0, n_authors-1): #last author loop is unnecessary\n",
    "        print(f\"Progress: {i/(n_authors-2)*100:.0f}%.\", end=\"\\r\")\n",
    "\n",
    "        # Initialize matrix\n",
    "        C = np.identity(n_authors-i)\n",
    "        C = C[:,1:]\n",
    "        C[0] = 1\n",
    "\n",
    "        # Main inner product\n",
    "        result = np.dot(papers_mat_i, C)\n",
    "\n",
    "        # Calculate number of collaborations\n",
    "        result = result - 1\n",
    "        result = result.clip(0)\n",
    "        collabs_author = result.sum(axis=0)\n",
    "\n",
    "        # Store in collabs vector\n",
    "        end_pos = start_pos + n_authors - i - 1\n",
    "\n",
    "        collabs[start_pos:end_pos] = collabs_author\n",
    "\n",
    "        # Update start_pos for writing next loop\n",
    "        start_pos = end_pos \n",
    "\n",
    "        # Remove first author from papers_mat for next loop\n",
    "        papers_mat_i = papers_mat_i[:,1:]\n",
    "\n",
    "    author_combinations = combinations(authors_index,2)\n",
    "    collabs_df = pd.DataFrame(list(author_combinations), columns=['source', 'target'])\n",
    "    collabs_df['value']=collabs\n",
    "\n",
    "    if save:\n",
    "        collabs_df.to_csv(f'./data/edgelist_{institution}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a627dcb7-49b2-44da-bdb5-280165222b8a",
   "metadata": {},
   "source": [
    "## Execute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41307be8-77a1-4b49-abcc-6e533bc33931",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select institution\n",
    "institution_list = ['IGTP']\n",
    "\n",
    "for institution in institution_list:\n",
    "    calculate_collaborations(institution, papers_df, res_df, save=True, threshold=100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
