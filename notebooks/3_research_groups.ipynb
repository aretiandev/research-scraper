{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7bd51148-b8a7-420c-b047-31f580987d9f",
   "metadata": {},
   "source": [
    "# Collapse at research group level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8779db2f-5419-42a6-8e86-c810bb5830bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53828f2b-575d-4707-a4a7-26d921fd3b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# institution_list = ['IGTP+', 'UPC_CIMNE', 'UB', 'UPF', 'UVic-UCC', 'UOC']\n",
    "# institution_list = ['UVic-UCC']\n",
    "\n",
    "for institution in institution_list:\n",
    "    print(f\"Institution: {institution}.\")\n",
    "    # Get Nodes\n",
    "\n",
    "    author_df = pd.read_csv(f'data/nodes_{institution}_20220309.csv', converters = {'groups': eval})\n",
    "    author_full = pd.read_csv(f'data/nodes_{institution}_full_20220309.csv', converters = {'groups': eval})\n",
    "    author_df = author_full.merge(author_df['id'], left_index=True, right_index=True)\n",
    "\n",
    "    # Filter nodelist for researchers with nonempty research groups\n",
    "    mask = author_df['groups'].apply(len) > 0\n",
    "    author_gp_df = author_df[mask]\n",
    "\n",
    "    # Clean data\n",
    "    author_gp_lst = list(author_gp_df['id'].unique())\n",
    "    author_gp_df.loc[:,'url_id'] = author_gp_df.loc[:,'groups'].apply(lambda x: x[0][1:])\n",
    "\n",
    "    # Create group level nodelist\n",
    "\n",
    "    # Get group names\n",
    "    group_df = pd.read_csv('data/groups.csv')\n",
    "    group_df = group_df[['name', 'url_id']]\n",
    "    author_gp_df = author_gp_df.merge(group_df, how='left', on='url_id')\n",
    "\n",
    "    # Collapse at group level\n",
    "    nodes_df = author_gp_df.groupby('url_id').first().reset_index()\n",
    "    nodes_df = nodes_df[['url_id','name', 'institution', 'institution_2', 'department', 'institution_group','n_publications']]\n",
    "    nodes_df = nodes_df.rename(columns={'url_id':'id', 'name':'label'})\n",
    "\n",
    "    # Save\n",
    "    nodes_df.to_csv(f'data/group_nodes_{institution}.csv', index=None)\n",
    "\n",
    "    # Create group level edgelist\n",
    "\n",
    "    edges_df = pd.read_csv(f'data/edges_{institution}_20220309.csv')\n",
    "    mask = edges_df.apply(lambda row: row['Source'] in author_gp_lst and row['Target'] in author_gp_lst, axis=1)\n",
    "    edges_gp_df = edges_df[mask]\n",
    "    edges_gp_df = edges_gp_df.merge(author_gp_df[['id', 'url_id']], how='left', left_on='Source', right_on='id')\n",
    "    edges_gp_df = edges_gp_df.rename(columns={'url_id':'Source_gp'})\n",
    "    edges_gp_df = edges_gp_df.merge(author_gp_df[['id', 'url_id']], how='left', left_on='Target', right_on='id')\n",
    "    edges_gp_df = edges_gp_df.rename(columns={'url_id':'Target_gp'})\n",
    "    edges_gp_df = edges_gp_df[['Source_gp', 'Target_gp', 'Weight']]\n",
    "    edges_gp_df.columns = ['Source', 'Target', 'Weight']\n",
    "    edges_gp_df = edges_gp_df.groupby(['Source', 'Target']).sum().reset_index()\n",
    "\n",
    "    # Save\n",
    "    edges_gp_df.to_csv(f'data/group_edges_{institution}.csv', index=None)\n",
    "    print(\"Done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce72c4f-1f42-4b09-bd6b-576487a68295",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Version of above function to export as Snakemake script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb43500b-689f-40e3-b871-2ba952cfaca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "institution_list = ['CRAG']\n",
    "date_today = '20220422'\n",
    "\n",
    "input_nodes = f'../data/{date_today}/{date_today}_nodes_{institution}.csv'\n",
    "input_groups = f'../data/{date_today}/{date_today}_group_data.csv'\n",
    "input_edges = f'../data/{date_today}/{date_today}_edges_{institution}.csv'\n",
    "output_nodes = f'data/group_nodes_{institution}.csv'\n",
    "output_edges = f'data/group_edges_{institution}.csv'\n",
    "\n",
    "for institution in institution_list:\n",
    "    print(f\"Institution: {institution}.\")\n",
    "    # Get Nodes\n",
    "    author_df = pd.read_csv(input_nodes, converters = {'groups': eval})\n",
    "#     author_full = pd.read_csv(f'../data/{date_today}/nodes_{institution}_full_20220309.csv', converters = {'groups': eval})\n",
    "#     author_df = author_full.merge(author_df['id'], left_index=True, right_index=True)\n",
    "\n",
    "    # Filter nodelist for researchers with nonempty research groups\n",
    "    mask = author_df['groups'].apply(len) > 0\n",
    "    author_gp_df = author_df[mask]\n",
    "\n",
    "    # Clean data\n",
    "    author_gp_lst = list(author_gp_df['id'].unique())\n",
    "\n",
    "    author_gp_df.loc[:,'url_id'] = author_gp_df.loc[:,'groups'].apply(lambda x: x[0][1:])\n",
    "\n",
    "    # Create group level nodelist\n",
    "\n",
    "    # Get group names\n",
    "    group_df = pd.read_csv(input_groups)\n",
    "\n",
    "    group_df['url_id'] = group_df['url'].str[31:]\n",
    "\n",
    "    group_df = group_df[['name', 'url_id']]\n",
    "    author_gp_df = author_gp_df.merge(group_df, how='left', on='url_id')\n",
    "\n",
    "    # Collapse at group level\n",
    "    nodes_df = author_gp_df.groupby('url_id').first().reset_index()\n",
    "\n",
    "    nodes_df = nodes_df[['url_id','name', 'institution', 'institution_2', 'department', 'institution_group','n_publications']]\n",
    "    nodes_df = nodes_df.rename(columns={'url_id':'id', 'name':'label'})\n",
    "\n",
    "    # Save\n",
    "#     nodes_df.to_csv(output_nodes, index=None)\n",
    "\n",
    "    # Create group level edgelist\n",
    "\n",
    "    edges_df = pd.read_csv(input_edges)\n",
    "\n",
    "    mask = edges_df.apply(lambda row: row['Source'] in author_gp_lst and row['Target'] in author_gp_lst, axis=1)\n",
    "    edges_gp_df = edges_df[mask]\n",
    "    edges_gp_df = edges_gp_df.merge(author_gp_df[['id', 'url_id']], how='left', left_on='Source', right_on='id')\n",
    "    edges_gp_df = edges_gp_df.rename(columns={'url_id':'Source_gp'})\n",
    "    edges_gp_df = edges_gp_df.merge(author_gp_df[['id', 'url_id']], how='left', left_on='Target', right_on='id')\n",
    "    edges_gp_df = edges_gp_df.rename(columns={'url_id':'Target_gp'})\n",
    "    edges_gp_df = edges_gp_df[['Source_gp', 'Target_gp', 'Weight']]\n",
    "    edges_gp_df.columns = ['Source', 'Target', 'Weight']\n",
    "    edges_gp_df = edges_gp_df.groupby(['Source', 'Target']).sum().reset_index()\n",
    "\n",
    "    # Save\n",
    "#     edges_gp_df.to_csv(output_edges, index=None)\n",
    "    print(\"Done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "812fd8f5-98f4-4ecd-85ed-0bdf11604a80",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d65d11-711e-40fb-bf01-a66d565c9258",
   "metadata": {},
   "outputs": [],
   "source": [
    "institution = 'UdL'\n",
    "date_today = '20220422'\n",
    "\n",
    "input_nodes = f'../data/{date_today}/{date_today}_nodes_{institution}.csv'\n",
    "input_groups = f'../data/{date_today}/{date_today}_group_data.csv'\n",
    "input_edges = f'../data/{date_today}/{date_today}_edges_{institution}.csv'\n",
    "output_nodes = f'data/group_nodes_{institution}.csv'\n",
    "output_edges = f'data/group_edges_{institution}.csv'\n",
    "\n",
    "print(f\"Institution: {institution}.\")\n",
    "# Get Nodes\n",
    "author_df = pd.read_csv(input_nodes, converters = {'groups': eval})\n",
    "\n",
    "# Filter nodelist for researchers with nonempty research groups\n",
    "mask = author_df['groups'].apply(len) > 0\n",
    "author_gp_df = author_df[mask]\n",
    "\n",
    "# Clean data\n",
    "author_gp_lst = list(author_gp_df['id'].unique())\n",
    "\n",
    "author_gp_df.loc[:,'url_id'] = author_gp_df.loc[:,'groups'].apply(lambda x: x[0][1:])\n",
    "\n",
    "# Create group level nodelist\n",
    "\n",
    "# Get group names\n",
    "group_df = pd.read_csv(input_groups)\n",
    "\n",
    "group_df['url_id'] = group_df['url'].str[31:]\n",
    "\n",
    "group_df = group_df[['name', 'url_id']]\n",
    "author_gp_df = author_gp_df.merge(group_df, how='left', on='url_id')\n",
    "\n",
    "# Collapse at group level\n",
    "nodes_df = author_gp_df.groupby('url_id').first().reset_index()\n",
    "\n",
    "nodes_df = nodes_df[['url_id','name', 'institution', 'institution_2', 'department', 'institution_group','n_publications']]\n",
    "nodes_df = nodes_df.rename(columns={'url_id':'id', 'name':'label'})\n",
    "\n",
    "# Save\n",
    "#     nodes_df.to_csv(output_nodes, index=None)\n",
    "\n",
    "# Create group level edgelist\n",
    "\n",
    "edges_df = pd.read_csv(input_edges)\n",
    "\n",
    "mask = edges_df.apply(lambda row: row['Source'] in author_gp_lst and row['Target'] in author_gp_lst, axis=1)\n",
    "edges_gp_df = edges_df[mask]\n",
    "edges_gp_df = edges_gp_df.merge(author_gp_df[['id', 'url_id']], how='left', left_on='Source', right_on='id')\n",
    "edges_gp_df = edges_gp_df.rename(columns={'url_id':'Source_gp'})\n",
    "edges_gp_df = edges_gp_df.merge(author_gp_df[['id', 'url_id']], how='left', left_on='Target', right_on='id')\n",
    "edges_gp_df = edges_gp_df.rename(columns={'url_id':'Target_gp'})\n",
    "edges_gp_df = edges_gp_df[['Source_gp', 'Target_gp', 'Weight']]\n",
    "edges_gp_df.columns = ['Source', 'Target', 'Weight']\n",
    "edges_gp_df = edges_gp_df.groupby(['Source', 'Target']).sum().reset_index()\n",
    "\n",
    "# Save\n",
    "#     edges_gp_df.to_csv(output_edges, index=None)\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b7d36b-bd23-4012-84e5-61bed18e8be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5b0470-520c-4ee1-b1c4-19dbeaf17b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "L|\\\\\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
