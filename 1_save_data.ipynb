{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9722fea-7375-40cd-be0d-91abd54100a6",
   "metadata": {},
   "source": [
    "# Save Data\n",
    "\n",
    "This notebook post-processed the scraped data from Portal de la Reserca and saves filtered versions of data to avoid wasting time later in the computing.\n",
    "\n",
    "**NOTE: you only need to run this notebook once. Every run will overwrite data that is the input of the following steps.** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d27f59b-cfdd-4f38-bcf0-38e4e5e44cd1",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "553d9af1-da9d-4718-b27a-45d4ef954fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from ast import literal_eval\n",
    "from itertools import combinations\n",
    "from datetime import date\n",
    "import itertools\n",
    "import random\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae84a20d-e53d-44ef-8531-9acea4b5b4c8",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Save papers by institution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc4de9a-b4b8-481a-9c67-9ca127c0429c",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cfc57f49-adbb-49dd-b756-42e94ca06496",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def convert_to_list(x):\n",
    "    \"\"\"Convert string column to list\"\"\"\n",
    "    try:\n",
    "        result = literal_eval(x)\n",
    "    except ValueError:\n",
    "        result = np.nan\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf7bb835-7b3e-4955-a088-675b45118982",
   "metadata": {},
   "source": [
    "## Combine scraped data into single file\n",
    "(takes ~5mins, often gets stuck)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cce7e15b-9a0a-4905-8f7f-e9acde871000",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine papers datasets that were downloaded in two batches\n",
    "# papers0_df = pd.read_csv('./data/papers_0.csv')\n",
    "# papers1_df = pd.read_csv('./data/papers_1.csv')\n",
    "# papers_df = papers0_df.append(papers1_df)\n",
    "# papers_df = papers_df.drop_duplicates()\n",
    "# papers_df.to_csv('./data/papers.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec76b1ab-62d5-48b7-923e-750a2c2e0009",
   "metadata": {},
   "source": [
    "## Load papers and authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46d49d47-a777-470c-b40d-0dff24e0b65e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set date\n",
    "os.environ['TZ'] = 'America/New_York'\n",
    "time.tzset()\n",
    "date_today = date.today().strftime(\"%Y%m%d\")\n",
    "date_today = '20220309'\n",
    "\n",
    "# Load papers\n",
    "papers_df = pd.read_csv('./data/papers.csv')\n",
    "# Debug:\n",
    "# papers_df_backup = papers_df.copy()\n",
    "# papers_df = papers_df_backup.copy()\n",
    "\n",
    "papers_df['orcids'] = papers_df['orcids'].apply(lambda x: convert_to_list(x))\n",
    "\n",
    "# Replace NaNs to empty lists to avoid loops from breaking\n",
    "mask = papers_df['orcids'].isna()\n",
    "papers_df.loc[mask, 'orcids'] = pd.Series([[] for _ in range(len(mask))])\n",
    "\n",
    "# Load authors\n",
    "authors_df = pd.read_csv(f'./data/nodes_{date_today}.csv')\n",
    "authors_df['institution'] = authors_df['institution'].apply(lambda x: convert_to_list(x))\n",
    "authors_df['projects'] = authors_df['projects'].apply(lambda x: convert_to_list(x))\n",
    "authors_df['groups'] = authors_df['groups'].apply(lambda x: convert_to_list(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c3bf86-5d0b-4395-9d99-e77f438b5873",
   "metadata": {},
   "source": [
    "## Create groups of institutions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f20438b5-2f31-4bb9-8f3b-0039c4a2a0fb",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd6c5fe2-1324-4e8c-b727-c34f064ada14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicate institutions\n",
    "authors_df['institution'] = authors_df['institution'].apply(lambda x: list(set(x)))\n",
    "\n",
    "# Helper function for assignment\n",
    "def assign_to_group(row, institution_list, label):\n",
    "    if bool(set(row['institution']) & set(institution_list)):\n",
    "#         print(lst)  # Debug\n",
    "        inst_groups = row['institution'].copy()\n",
    "        inst_groups.append(label)\n",
    "#         print(lst_extended)  # Debug\n",
    "        return inst_groups\n",
    "    else:\n",
    "        return row['institution_group']\n",
    "\n",
    "# Append missing acronyms: IGTP + IJC + IrsiCaixa\n",
    "acronym_dict = {\n",
    "    'IJC':'Institut de Recerca contra la LeucÃ¨mia Josep Carreras', \n",
    "    'IrsiCaixa':'IrsiCaixa AIDS Research Institute' }\n",
    "\n",
    "def add_acronym(row):\n",
    "    for acronym, name in acronym_dict.items():\n",
    "        if row['institution_2'] == name:\n",
    "            row['institution'].append(acronym)\n",
    "    return row['institution']\n",
    "\n",
    "authors_df['institution'] = authors_df.apply(add_acronym, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a6411a6-fa54-4a0d-ad0a-ef988de1a844",
   "metadata": {},
   "source": [
    "### Assign to groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ace39bd-545f-4cf6-9491-66e886ff9e97",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create groups of institutions\n",
    "authors_df['institution_group'] = authors_df['institution']\n",
    "\n",
    "# Assign to UPC + CIMNE\n",
    "institution_list = ['UPC', 'CIMNE']\n",
    "label = 'UPC_CIMNE'\n",
    "authors_df['institution_group'] = authors_df.apply(\n",
    "                                    lambda x: assign_to_group(x, institution_list, label), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c9e23806-d187-4e20-854a-ebd18177cb98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign to IGTP}\n",
    "institution_list = ['IGTP', 'IJC', 'IrsiCaixa']\n",
    "label = 'IGTP+'\n",
    "authors_df['institution_group'] = authors_df.apply(\n",
    "                                    lambda x: assign_to_group(x, institution_list, label), axis=1)\n",
    "\n",
    "# Drop duplicate institution groups\n",
    "authors_df['institution_group'] = authors_df['institution_group'].apply(lambda x: list(set(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "049ffad5-7d83-4941-ae1f-beffc32672eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# authors_df\n",
    "\n",
    "# institution = 'UPC'\n",
    "# mask = authors_df['institution'].apply(lambda x: institution in x)\n",
    "# mask.sum()\n",
    "# institution = 'UPC_CIMNE'\n",
    "# mask = authors_df['institution_group'].apply(lambda x: institution in x)\n",
    "# mask.sum()\n",
    "# mask\n",
    "# authors_inst_df = authors_df.copy()[mask]\n",
    "# authors_inst_df\n",
    "\n",
    "# sorted(list(set(authors_df['institution_group'].sum())))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3543b81-717d-413d-b659-e5c037a0fc00",
   "metadata": {},
   "source": [
    "## Filter and save authors and papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "71d097f0-d99f-47a4-8aea-8c460b86503c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing institution group: IGTP+.\n",
      "Adding projects and groups.\n",
      "Saved './data/nodes_IGTP+_20220309.csv'.\n",
      "Extracting papers of researchers from IGTP+.\n",
      "Extracting papers with more than 2 authors.\n",
      "Saved './data/papers_IGTP+_20220309.csv'.\n",
      "Saved './data/papers_IGTP+_2plus_20220309.csv'.\n",
      "\n",
      "Processing institution group: UPC_CIMNE.\n",
      "Adding projects and groups.\n",
      "Saved './data/nodes_UPC_CIMNE_20220309.csv'.\n",
      "Extracting papers of researchers from UPC_CIMNE.\n",
      "Extracting papers with more than 2 authors.\n",
      "Saved './data/papers_UPC_CIMNE_20220309.csv'.\n",
      "Saved './data/papers_UPC_CIMNE_2plus_20220309.csv'.\n",
      "\n",
      "Processing institution group: UB.\n",
      "Adding projects and groups.\n",
      "Saved './data/nodes_UB_20220309.csv'.\n",
      "Extracting papers of researchers from UB.\n",
      "Extracting papers with more than 2 authors.\n",
      "Saved './data/papers_UB_20220309.csv'.\n",
      "Saved './data/papers_UB_2plus_20220309.csv'.\n",
      "\n",
      "Processing institution group: UPF.\n",
      "Adding projects and groups.\n",
      "Saved './data/nodes_UPF_20220309.csv'.\n",
      "Extracting papers of researchers from UPF.\n",
      "Extracting papers with more than 2 authors.\n",
      "Saved './data/papers_UPF_20220309.csv'.\n",
      "Saved './data/papers_UPF_2plus_20220309.csv'.\n",
      "\n",
      "Processing institution group: UVic-UCC.\n",
      "Adding projects and groups.\n",
      "Saved './data/nodes_UVic-UCC_20220309.csv'.\n",
      "Extracting papers of researchers from UVic-UCC.\n",
      "Extracting papers with more than 2 authors.\n",
      "Saved './data/papers_UVic-UCC_20220309.csv'.\n",
      "Saved './data/papers_UVic-UCC_2plus_20220309.csv'.\n",
      "\n",
      "Processing institution group: UOC.\n",
      "Adding projects and groups.\n",
      "Saved './data/nodes_UOC_20220309.csv'.\n",
      "Extracting papers of researchers from UOC.\n",
      "Extracting papers with more than 2 authors.\n",
      "Saved './data/papers_UOC_20220309.csv'.\n",
      "Saved './data/papers_UOC_2plus_20220309.csv'.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "institution_group_list = ['IGTP+', 'UPC_CIMNE', 'UB', 'UPF', 'UVic-UCC', 'UOC']\n",
    "# institution_group_list = ['UB']\n",
    "# institution_group_list = ['IGTP+']\n",
    "# institution_group_list = ['UPC_CIMNE']\n",
    "\n",
    "for institution in institution_group_list:\n",
    "    print(f\"Processing institution group: {institution}.\")\n",
    "    \n",
    "    # Extract authors from institution\n",
    "    mask = authors_df['institution_group'].apply(lambda x: institution in x)\n",
    "    authors_inst_df = authors_df.copy()[mask]\n",
    "#     authors_inst_df = authors_df.copy().loc[authors_df['institution_group'] == institution]\n",
    "    \n",
    "    # Calculate number of affiliations\n",
    "    authors_inst_df['n_affiliations'] = authors_inst_df.copy()['institution'].apply(len)\n",
    "\n",
    "    # Calculate if single or multiple affilations\n",
    "    authors_inst_df['single_affiliation'] = 'Multiple affiliations'\n",
    "    mask = authors_inst_df['n_affiliations'] == 1\n",
    "    authors_inst_df.loc[mask, 'single_affiliation'] = authors_inst_df.loc[mask, 'institution'].apply(lambda x: x[0])\n",
    "    \n",
    "    # Add projects and groups\n",
    "    print(\"Adding projects and groups.\")\n",
    "    authors_inst_df['n_projects'] = authors_inst_df['projects'].apply(len)\n",
    "    authors_inst_df['n_groups']   = authors_inst_df['groups'].apply(len)\n",
    "\n",
    "    # Save\n",
    "    out_file = f'./data/nodes_{institution}_{date_today}.csv'\n",
    "    authors_inst_df.to_csv(out_file, index=None)\n",
    "    print(f\"Saved '{out_file}'.\")\n",
    "\n",
    "    # Extract papers with authors from institution\n",
    "    print(f\"Extracting papers of researchers from {institution}.\")\n",
    "    authors_inst = authors_inst_df['id'].unique() # Get list of authors\n",
    "    mask_1plus = papers_df['orcids'].apply(lambda x: bool(set(x) & set(authors_inst)))\n",
    "    # Debug:\n",
    "#     mask_1plus_backup = mask_1plus.copy()\n",
    "#     mask_1plus = mask_1plus_backup.copy()\n",
    "    print(\"Extracting papers with more than 2 authors.\")\n",
    "    mask_2plus = papers_df.loc[mask_1plus, 'orcids'].apply(lambda x: len(set(x) & set(authors_inst)) > 1)\n",
    "    papers_inst_1plus_df = papers_df[mask_1plus]\n",
    "    papers_inst_2plus_df = papers_df[mask_1plus][mask_2plus]\n",
    "    \n",
    "    # Save\n",
    "    out_file_1 = f'./data/papers_{institution}_{date_today}.csv'\n",
    "    out_file_2 = f'./data/papers_{institution}_2plus_{date_today}.csv'\n",
    "    papers_inst_1plus_df.to_csv(out_file_1, index=None)\n",
    "    papers_inst_2plus_df.to_csv(out_file_2, index=None)\n",
    "    print(f\"Saved '{out_file_1}'.\")\n",
    "    print(f\"Saved '{out_file_2}'.\")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7b33637a-0a62-4634-833c-3eaee0c96f38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UOC\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "370"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(institution)\n",
    "mask = authors_df['institution_group'].apply(lambda x: institution in x)\n",
    "mask.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee528831-4e5f-4a51-81ca-f9a38c75bde7",
   "metadata": {},
   "source": [
    "# Add variables to nodelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "867b65ba-469f-4e18-ba34-93b66e71892c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Institution: IGTP+.\n",
      "Adding publications number and types to nodelist. This might take a while...\n",
      "Done.\n",
      "Saved ./data/nodes_IGTP+_full_20220309.csv.\n",
      "\n",
      "Institution: UPC_CIMNE.\n",
      "Adding publications number and types to nodelist. This might take a while...\n",
      "Done.\n",
      "Saved ./data/nodes_UPC_CIMNE_full_20220309.csv.\n",
      "\n",
      "Institution: UB.\n",
      "Adding publications number and types to nodelist. This might take a while...\n",
      "Done.\n",
      "Saved ./data/nodes_UB_full_20220309.csv.\n",
      "\n",
      "Institution: UPF.\n",
      "Adding publications number and types to nodelist. This might take a while...\n",
      "Done.\n",
      "Saved ./data/nodes_UPF_full_20220309.csv.\n",
      "\n",
      "Institution: UVic-UCC.\n",
      "Adding publications number and types to nodelist. This might take a while...\n",
      "Done.\n",
      "Saved ./data/nodes_UVic-UCC_full_20220309.csv.\n",
      "\n",
      "Institution: UOC.\n",
      "Adding publications number and types to nodelist. This might take a while...\n",
      "Done.\n",
      "Saved ./data/nodes_UOC_full_20220309.csv.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "date_today = '20220309'\n",
    "institution_list = ['IGTP+', 'UPC_CIMNE', 'UB', 'UPF', 'UVic-UCC', 'UOC']\n",
    "# institution_list = ['UB']\n",
    "# institution_list = ['IGTP+']\n",
    "# institution_list = ['UPC_CIMNE']\n",
    "\n",
    "for institution in institution_list:\n",
    "    print(f\"Institution: {institution}.\")\n",
    "    \n",
    "    # Load authors\n",
    "    authors_inst_df = pd.read_csv(f'./data/nodes_{institution}_{date_today}.csv')\n",
    "    authors_inst_df = authors_inst_df.set_index('id')\n",
    "    \n",
    "    # Load papers\n",
    "    papers_inst_df = pd.read_csv(f'./data/papers_{institution}_{date_today}.csv', converters = {'orcids': eval})\n",
    "    # Get papers column\n",
    "    papers = papers_inst_df[['orcids', 'type']].copy()\n",
    "    papers = papers.reset_index(drop=True)\n",
    "\n",
    "    # Create unique list of authors from papers\n",
    "#     authors_index = list(set(papers.sum()))\n",
    "#     authors_index.sort()\n",
    "\n",
    "    # Create unique list of paper ids\n",
    "#     papers_index = list(papers_inst_df['url_id'].unique())\n",
    "#     papers_index.sort()\n",
    "    \n",
    "    # Publication type: ['Journal Article', 'Chapter in Book', 'Book', 'NaN']\n",
    "    authors_inst_df['n_publications'] = 0\n",
    "    authors_inst_df['n_articles'] = 0\n",
    "    authors_inst_df['n_chapters'] = 0\n",
    "    authors_inst_df['n_books'] = 0\n",
    "    authors_inst_df['n_other'] = 0\n",
    "    \n",
    "    paper_types = {'Journal Article':'n_articles', 'Chapter in Book':'n_chapters', 'Book':'n_books'}\n",
    "    \n",
    "    def add_publication_stats(paper):\n",
    "#         print(f\"Progress: {index/len(papers)*100:.0f}%. Paper: {index:,d}/{len(papers):,d}.\", end=\"\\r\")\n",
    "        for orcid in paper['orcids']:\n",
    "            # Add publication\n",
    "            try:\n",
    "                authors_inst_df.loc[orcid, 'n_publications'] += 1\n",
    "            except KeyError: # author is not in the institution\n",
    "                continue\n",
    "                \n",
    "            # Assign type\n",
    "            assigned_type = False\n",
    "            for paper_type, column in paper_types.items():\n",
    "                if paper['type'] == paper_type:\n",
    "                    authors_inst_df.loc[orcid, column] +=1\n",
    "                    assigned_type = True\n",
    "                    break\n",
    "            if not assigned_type:\n",
    "                authors_inst_df.loc[orcid, 'n_other'] +=1\n",
    "    \n",
    "    print(\"Adding publications number and types to nodelist. This might take a while...\")\n",
    "#     t1 = time.perf_counter()\n",
    "    papers.apply(lambda x: add_publication_stats(x), axis=1)\n",
    "#     t2 = time.perf_counter()\n",
    "#     print(f\"Lambda function time: {t2-t1:.2f} seconds.\")\n",
    "            \n",
    "    \n",
    "#     print(\"Starting for loop.\")\n",
    "#     t3 = time.perf_counter()\n",
    "#     for index, paper in papers.iterrows():\n",
    "#         print(f\"Progress: {index/len(papers)*100:.0f}%. Paper: {index:,d}/{len(papers):,d}.\", end=\"\\r\")\n",
    "#         for orcid in paper['orcids']:\n",
    "#             # Add publication\n",
    "#             try:\n",
    "#                 authors_inst_df.loc[orcid, 'n_publications'] += 1\n",
    "#             except KeyError: # author is not in the institution\n",
    "#                 continue\n",
    "                \n",
    "#             # Assign type\n",
    "#             assigned_type = False\n",
    "#             for paper_type, column in paper_types.items():\n",
    "#                 if paper['type'] == paper_type:\n",
    "#                     authors_inst_df.loc[orcid, column] +=1\n",
    "#                     assigned_type = True\n",
    "#                     break\n",
    "#             if not assigned_type:\n",
    "#                 authors_inst_df.loc[orcid, 'n_other'] +=1\n",
    "#     t4 = time.perf_counter()\n",
    "#     print(f\"For loop time: {t4-t2:.2f} seconds.\")\n",
    "            \n",
    "                    \n",
    "    # Save\n",
    "    out_file = f'./data/nodes_{institution}_full_{date_today}.csv'\n",
    "    authors_inst_df.to_csv(out_file, index=None)\n",
    "    print(\"Done.\")\n",
    "    print(f\"Saved {out_file}.\")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8c3681-c109-4067-ab87-07f213eb4241",
   "metadata": {},
   "outputs": [],
   "source": [
    "# authors_inst_df = pd.read_csv(f'./data/nodes_{institution}_{date_today}.csv')\n",
    "# authors_inst_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a8efc9-8f8a-4e3e-86c6-46fe5a88194c",
   "metadata": {
    "tags": []
   },
   "source": [
    "# EXTRA CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a760d96d-9398-4ea4-a4b7-ce5d282b0dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# authors_df['institution']\n",
    "# institution = 'UB'\n",
    "# authors_inst_df = authors_df.copy().loc[authors_df['institution_group'] == institution]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7420d841-41be-4071-9d1f-36a6ef252989",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Add publication variables to nodelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9e26ec-0466-4bd0-94a4-5e02399c1b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_today = '20220309'\n",
    "institution_list = ['IGTP+', 'UPC_CIMNE', 'UB', 'UPF', 'UVic-UCC', 'UOC']\n",
    "institution_list = ['UB']\n",
    "institution_list = ['IGTP+']\n",
    "\n",
    "for institution in institution_list:\n",
    "    print(f\"Institution: {institution}.\")\n",
    "    \n",
    "    # Load authors\n",
    "    authors_inst_df = pd.read_csv(f'./data/nodes_{institution}_{date_today}.csv')\n",
    "    authors_inst_df = authors_inst_df.set_index('id')\n",
    "    \n",
    "    # Load papers\n",
    "    papers_inst_df = pd.read_csv(f'./data/papers_{institution}_{date_today}.csv', converters = {'orcids': eval})\n",
    "    # Get papers column\n",
    "    papers = papers_inst_df[['orcids', 'type']].copy()\n",
    "    papers = papers.reset_index(drop=True)\n",
    "\n",
    "    # Create unique list of authors from papers\n",
    "#     authors_index = list(set(papers.sum()))\n",
    "#     authors_index.sort()\n",
    "\n",
    "    # Create unique list of paper ids\n",
    "#     papers_index = list(papers_inst_df['url_id'].unique())\n",
    "#     papers_index.sort()\n",
    "    \n",
    "    # Publication type: ['Journal Article', 'Chapter in Book', 'Book', 'NaN']\n",
    "    authors_inst_df['n_publications'] = 0\n",
    "    authors_inst_df['n_articles'] = 0\n",
    "    authors_inst_df['n_chapters'] = 0\n",
    "    authors_inst_df['n_books'] = 0\n",
    "    authors_inst_df['n_other'] = 0\n",
    "    \n",
    "    paper_types = {'Journal Article':'n_articles', 'Chapter in Book':'n_chapters', 'Book':'n_books'}\n",
    "    \n",
    "    def add_publcation_stats(orcids):\n",
    "#         print(f\"Progress: {index/len(papers)*100:.0f}%. Paper: {index:,d}/{len(papers):,d}.\", end=\"\\r\")\n",
    "        for orcid in orcids:\n",
    "            # Add publication\n",
    "            try:\n",
    "                authors_inst_df.loc[orcid, 'n_publications'] += 1\n",
    "            except KeyError: # author is not in the institution\n",
    "                continue\n",
    "                \n",
    "            # Assign type\n",
    "            assigned_type = False\n",
    "            for paper_type, column in paper_types.items():\n",
    "                if paper['type'] == paper_type:\n",
    "                    authors_inst_df.loc[orcid, column] +=1\n",
    "                    assigned_type = True\n",
    "                    break\n",
    "            if not assigned_type:\n",
    "                authors_inst_df.loc[orcid, 'n_other'] +=1\n",
    "    \n",
    "    import time\n",
    "    t1 = time.perf_counter()\n",
    "    papers.apply(lambda x: add_publication_stats(x))\n",
    "    t2 = time.perf_counter()\n",
    "    print(f\"Lambda function time: {t2-t1:.2f} seconds.\"\n",
    "            \n",
    "    \n",
    "    t1 = time.perf_counter()\n",
    "    for index, paper in papers.iterrows():\n",
    "        print(f\"Progress: {index/len(papers)*100:.0f}%. Paper: {index:,d}/{len(papers):,d}.\", end=\"\\r\")\n",
    "        for orcid in paper['orcids']:\n",
    "            # Add publication\n",
    "            try:\n",
    "                authors_inst_df.loc[orcid, 'n_publications'] += 1\n",
    "            except KeyError: # author is not in the institution\n",
    "                continue\n",
    "                \n",
    "            # Assign type\n",
    "            assigned_type = False\n",
    "            for paper_type, column in paper_types.items():\n",
    "                if paper['type'] == paper_type:\n",
    "                    authors_inst_df.loc[orcid, column] +=1\n",
    "                    assigned_type = True\n",
    "                    break\n",
    "            if not assigned_type:\n",
    "                authors_inst_df.loc[orcid, 'n_other'] +=1\n",
    "    t2 = time.perf_counter()\n",
    "    print(f\"For loop time: {t2-t1:.2f} seconds.\"\n",
    "            \n",
    "                    \n",
    "    # Save\n",
    "    out_file = f'./data/nodes_{institution}_full_{date_today}.csv'\n",
    "    authors_inst_df.to_csv(out_file, index=None)\n",
    "    print(\"Done.\")\n",
    "    print(f\"Saved {out_file}.\")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96bebdd4-4c6d-4816-9141-4a27ea174f58",
   "metadata": {},
   "source": [
    "## Create matrix of papers\n",
    "This strategy creates 1,0 matrices where each row is a paper and each column is an author. It is a cool strategy but unfortunately very expensive in terms of resources. The script takes too long to run and the output are 500MB files. It is better to just collect results researcher by researcher."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c1f844-e3af-4f54-9125-96dcbd36315a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "date_today = '20220309'\n",
    "institution_list = ['IGTP+', 'UPC_CIMNE', 'UB', 'UPF', 'UVic-UCC', 'UOC']\n",
    "# institution_list = ['IGTP+']\n",
    "\n",
    "for institution in institution_list:\n",
    "    print(f\"Processing institution: {institution}.\")\n",
    "    # Read paper from instituion\n",
    "    papers_inst_df = pd.read_csv(f'./data/papers_{institution}_{date_today}.csv', converters = {'orcids': eval})\n",
    "    papers_orcids_df = papers_inst_df[['url_id', 'orcids']]\n",
    "\n",
    "    # Fix list of orcids that contains 'null'\n",
    "    mask = papers_orcids_df['orcids'].apply(lambda x: bool('null' in x))\n",
    "    try:\n",
    "        print(f\"Replaced 'null' value in paper: {papers_orcids_df.loc[mask, 'orcids'].values[0]}\")\n",
    "        papers_orcids_df.loc[mask, 'orcids'].values[0].remove('null')\n",
    "    except IndexError: # all rows in the mask are False\n",
    "        pass\n",
    "\n",
    "    # Sort and index\n",
    "    papers_orcids_df = papers_orcids_df.sort_values(by='url_id')\n",
    "    papers_orcids_df = papers_orcids_df.set_index('url_id')\n",
    "    \n",
    "    # Convert list to long df\n",
    "    print(\"Converting lists to long df.\")\n",
    "    papers_matrix = papers_orcids_df.explode('orcids').reset_index()\n",
    "    papers_matrix['count'] = 1\n",
    "\n",
    "    # Long to wide\n",
    "    print(\"Converting long df to wide df.\")\n",
    "    papers_matrix = papers_matrix.pivot_table(index='url_id', columns='orcids', values='count', aggfunc=sum)\n",
    "\n",
    "    # Replace NaNs\n",
    "    papers_matrix = papers_matrix.fillna(0)\n",
    "\n",
    "    # Sort orcids in columns\n",
    "    papers_matrix = papers_matrix.reindex(sorted(papers_matrix.columns), axis=1)\n",
    "    \n",
    "    # Save\n",
    "    out_file = f'data/papers_matrix_{institution}.csv'\n",
    "    papers_matrix.to_csv(out_file)\n",
    "    print(f\"Saved '{out_file}'.\")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27e6ec3-157c-4987-b367-0354bdcf84b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "                    \n",
    "                    \n",
    "    # Create boolean matrix with papers\n",
    "#     paper_bool_df = pd.DataFrame(columns=authors_index, index=papers_index)\n",
    "    \n",
    "#     for i, paper in enumerate(papers):\n",
    "#         paper_bool_df.loc[i,:] = 0\n",
    "#         for orcid in paper:\n",
    "#             paper_bool_df.loc[i,orcid] = 1\n",
    "\n",
    "#     paper_bool_df.to_csv(f\"./data/paper_author_matrix_{institution}.csv\", index=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
